{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing nCRP tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}  # Dictionary to store child nodes\n",
    "        self.documents = 0  # Number of documents passing through this node (i.e. number of customers)\n",
    "        self.vocab = {}\n",
    "\n",
    "class nCRPTree:\n",
    "    def __init__(self, alpha):\n",
    "        self.root = Node()\n",
    "        self.alpha = alpha  # Concentration parameter\n",
    "\n",
    "    def sample_new_path(self, max_depth):\n",
    "        \"\"\"\n",
    "        Sample a path through the tree using the nCRP.\n",
    "\n",
    "        Parameters:\n",
    "        - max_depth: the maximum depth (number of levels) of the tree (i.e. L-level tree). \n",
    "                    L >= 1 (if L == 1, it only contains the root.)\n",
    "        Returns:\n",
    "        - path: a list of topics representing the path through the tree\n",
    "        \"\"\"\n",
    "        current_node = self.root\n",
    "        current_node.documents += 1\n",
    "        path = [] # not considering the root\n",
    "\n",
    "        for level in range(1,max_depth):\n",
    "            # Use the CRP function to sample a topic\n",
    "            sampled_topic = self.CRP(current_node)\n",
    "            path.append(sampled_topic)\n",
    "\n",
    "            # create new table if needed\n",
    "            if sampled_topic not in current_node.children.keys():\n",
    "                current_node.children[sampled_topic] = Node()\n",
    "            \n",
    "            # Move to the next node in the path\n",
    "            current_node = current_node.children[sampled_topic]\n",
    "            current_node.documents += 1\n",
    "\n",
    "        return path\n",
    "\n",
    "    def CRP(self, node):\n",
    "        \"\"\"\n",
    "        Basic CRP process.\n",
    "        \n",
    "        Returns:\n",
    "        - sampled_topic: label of the sampled topic(Not the Node)\n",
    "        \"\"\"\n",
    "        total_documents = node.documents #including the incoming document\n",
    "        topic_probabilities = {}\n",
    "        \n",
    "        # There are no table, so we have to get a new table with probability 1\n",
    "        if not node.children:\n",
    "            return np.int64(1) # the new table has a key = 1\n",
    "        \n",
    "        else:\n",
    "            # Calculating the probability of joining each of the existing tables (topics)\n",
    "            for topic, child_node in node.children.items():\n",
    "                topic_probabilities[topic] = child_node.documents / (self.alpha + total_documents - 1)\n",
    "\n",
    "            # Probability of creating a new table (topic)\n",
    "            new_table_key = np.max(topic) + 1\n",
    "            topic_probabilities[new_table_key] = self.alpha / (self.alpha + total_documents - 1)\n",
    "\n",
    "            topics = list(topic_probabilities.keys())\n",
    "            probabilities = list(topic_probabilities.values())\n",
    "\n",
    "            # Since probabilities sum to 1, normalization is not needed\n",
    "            sampled_topic = np.random.choice(topics, p=probabilities)\n",
    "\n",
    "            return sampled_topic\n",
    "    \n",
    "    def generate_initial_paths(self, corpus, max_depth):\n",
    "        \"\"\"\n",
    "        Generate initial paths for each document in the corpus using the nCRP tree.\n",
    "\n",
    "        Parameters:\n",
    "        - corpus: A list of documents (each document is a list of words)\n",
    "        - max_depth: Maximum depth (number of levels) of the tree\n",
    "\n",
    "        Returns:\n",
    "        - initial_paths: A dictionary mapping document index to its initial sampled path\n",
    "        \"\"\"\n",
    "        paths = {}\n",
    "\n",
    "        # Loop through each document in the corpus\n",
    "        for i, doc in enumerate(corpus):\n",
    "            path = self.sample_new_path(max_depth)  # Sample a path for the document\n",
    "            paths[i] = path  # Store the path with document index as key\n",
    "\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing nCRP process and initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example corpus\n",
    "corpus = [\n",
    "    [\"apple\", \"banana\"],            # Document 1\n",
    "    [\"cat\", \"dog\", \"fish\"],         # Document 2\n",
    "    [\"car\", \"bike\"],                # Document 3\n",
    "]\n",
    "corpus1 = [\n",
    "    [\"apple\", \"banana\", \"orange\", \"grape\", \"melon\"],     # Document 1\n",
    "    [\"cat\", \"dog\", \"fish\", \"bird\", \"hamster\"],           # Document 2\n",
    "    [\"car\", \"bike\", \"bus\", \"train\", \"plane\", \"ship\"],    # Document 3\n",
    "    [\"house\", \"building\", \"apartment\", \"cabin\"],         # Document 4\n",
    "    [\"sun\", \"moon\", \"stars\", \"galaxy\"],                  # Document 5\n",
    "    [\"river\", \"lake\", \"ocean\", \"sea\"],                   # Document 6\n",
    "    [\"earth\", \"mars\", \"jupiter\", \"saturn\", \"venus\"],     # Document 7\n",
    "]\n",
    "\n",
    "# Initialize the tree and set parameters\n",
    "alpha = 1.0\n",
    "tree = nCRPTree(alpha)\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Paths for Each Document:\n",
      "Document 1 Path: [np.int64(2), np.int64(3), np.int64(1)]\n",
      "Document 2 Path: [np.int64(2), np.int64(3), np.int64(2)]\n",
      "Document 3 Path: [np.int64(2), np.int64(2), np.int64(2)]\n",
      "Initial Paths for Each Document:\n",
      "Document 1 Path: [np.int64(3), np.int64(1), np.int64(1)]\n",
      "Document 2 Path: [np.int64(4), np.int64(1), np.int64(1)]\n",
      "Document 3 Path: [np.int64(2), np.int64(2), np.int64(3)]\n",
      "Document 4 Path: [np.int64(2), np.int64(2), np.int64(3)]\n",
      "Document 5 Path: [np.int64(2), np.int64(4), np.int64(2)]\n",
      "Document 6 Path: [np.int64(2), np.int64(2), np.int64(3)]\n",
      "Document 7 Path: [np.int64(2), np.int64(1), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "# Generate initial paths for all documents in the corpus\n",
    "initial_paths = tree.generate_initial_paths(corpus, max_depth)\n",
    "initial_paths1 = tree.generate_initial_paths(corpus1, max_depth)\n",
    "\n",
    "# Print the initial paths for each document\n",
    "print(\"Initial Paths for Each Document:\")\n",
    "for doc_id, path in initial_paths.items():\n",
    "    print(f\"Document {doc_id + 1} Path: {path}\")\n",
    "    \n",
    "print(\"Initial Paths for Each Document:\")\n",
    "for doc_id, path in initial_paths1.items():\n",
    "    print(f\"Document {doc_id + 1} Path: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA3288",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
